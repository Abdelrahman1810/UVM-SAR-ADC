# UVM-SAR-ADC

This repository contains a **Universal Verification Methodology (UVM)** testbench for verifying a **Successive Approximation Register Analog-to-Digital Converter (SAR-ADC)** design. The project showcases a complete functional verification environment using industry-standard UVM practices.

> [!IMPORTANT]
> The RTL design files for the SAR-ADC RTL are sourced externally and are not created by me, done by [UVM AMS TEAM](https://docs.google.com/document/d/1hYTKV5uwAwiOqRAxozzYEXZuelAb0_p5_eVgXfvsk0M/edit?usp=sharing). This repository focuses only on the verification environment using UVM.

## ğŸ§ª Project Description

The goal of this project is to verify a SAR-ADC RTL design using a fully layered UVM testbench. The testbench is structured to enable:

- Stimulus generation and randomized testing
- Transaction-level modeling
- Scoreboarding and coverage collection
- Reusability and scalability for future analog/digital mixed-signal designs

---

## ğŸ§  Test Strategy

This project supports different modes of running tests:

- **Single Test Run**: Runs one UVM test to verify a specific scenario or feature.
- **Multiple Test Run (Sequential)**: Runs multiple tests one after another. Useful for batch verification and regression.
- **Multiple Test Run (Parallel)**: Runs multiple UVM tests concurrently to speed up simulation time and improve runtime efficiency, especially for long test regressions or large test suites.

<!-- > ğŸ’¡ **Note:** Running tests in **parallel** significantly enhances simulation performance by reducing the overall execution time compared to running them sequentially. -->

> [!NOTE]
> Running tests in **parallel** significantly enhances simulation performance by reducing the overall execution time compared to running all sequences in single test or running multiple test sequentially.
---

##  UVM hierarchy

```sh
â””â”€â”€ UVM-SAR-ADC/
    â”œâ”€â”€ UVM/
    â”‚   â”œâ”€â”€ interface
    â”‚   â”‚   â””â”€â”€ AES_intf.sv
    â”‚   â”œâ”€â”€ objects
    â”‚   â”‚   â”œâ”€â”€ configration
    â”‚   â”‚   â”‚   â””â”€â”€ configration.sv
    â”‚   â”‚   â”œâ”€â”€ sequenceItem
    â”‚   â”‚   â”‚   â””â”€â”€ sequenceItem.sv
    â”‚   â”‚   â””â”€â”€ sequences
    â”‚   â”‚       â”œâ”€â”€ main_sequence.sv
    â”‚   â”‚       â”œâ”€â”€ rst_sequence.sv
    â”‚   â”‚       â”œâ”€â”€ mode1_sequence.sv
    â”‚   â”‚       â”œâ”€â”€ mode2_sequence.sv
    â”‚   â”‚       â”œâ”€â”€ mode3_sequence.sv
    â”‚   â”‚       â””â”€â”€ mode4_sequence.sv
    â”‚   â”œâ”€â”€ shared_pkg
    â”‚   â”‚   â””â”€â”€ shared_pkg.sv
    â”‚   â””â”€â”€ testbench_top
    â”‚       â”œâ”€â”€ test
    â”‚       â”‚   â”œâ”€â”€ env
    â”‚       â”‚   â”‚   â”œâ”€â”€ env.sv
    â”‚       â”‚   â”‚   â”œâ”€â”€ agent
    â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ agent.sv
    â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ monitor
    â”‚       â”‚   â”‚   â”‚   â”‚   â””â”€â”€ monitor.sv
    â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ driver
    â”‚       â”‚   â”‚   â”‚   â”‚   â””â”€â”€ driver.sv
    â”‚       â”‚   â”‚   â”‚   â””â”€â”€ sequencer
    â”‚       â”‚   â”‚   â”‚       â””â”€â”€ sequencer.sv
    â”‚       â”‚   â”‚   â”œâ”€â”€ scoreboard
    â”‚       â”‚   â”‚   â”‚   â””â”€â”€ scoreboard.sv
    â”‚       â”‚   â”‚   â””â”€â”€ subscriber
    â”‚       â”‚   â”‚       â””â”€â”€ subscriber.sv
    â”‚       â”‚   â””â”€â”€ test.sv
    â”‚       â””â”€â”€ top.sv
    â”œâ”€â”€ SAR_ADC_RTL/
    â”‚   â”œâ”€â”€ ...
    â”‚   â”œâ”€â”€ ...
    â”‚   â””â”€â”€ ...
    â”œâ”€â”€ Reports/
    â”‚   â””â”€â”€ ...
    â”œâ”€â”€ Simulation/
    â”‚   â”œâ”€â”€ Makefile
    â”‚   â”œâ”€â”€ extracted.py
    â”‚   â”œâ”€â”€ run_tests_parallel.bat
    â”‚   â”œâ”€â”€ run_tests_parallel.sh
    â”‚   â”œâ”€â”€ run_MultiTest_Parallel.tcl
    â”‚   â”œâ”€â”€ run_MultiTest_Sequential.tcl
    â”‚   â”œâ”€â”€ run_SingleTest.tcl
    â”‚   â””â”€â”€ srcfiles_dms.f
    â””â”€â”€ UCDB_files/
        â””â”€â”€ ...
```



## ğŸ”§ Prerequisites

To run this project, you will need:

- **SystemVerilog Simulator** (e.g., [QuestaSim](https://eda.sw.siemens.com/en-US/ic/questa/))
- **UVM Library** (usually comes with simulator or install separately)
- A Unix-like environment for using Makefile (Linux, macOS, or WSL on Windows)

---

## â–¶ï¸ Running on Windows

### 1. Open Command Prompt (CMD)

### 2. Clone the Repository

    git clone https://github.com/Abdelrahman1810/UVM-SAR-ADC.git
    cd UVM-SAR-ADC

### 3. Run the Simulation
ğŸ”¹ Single Test

- `Without GUI`

    ```
    make win_simSingleTest
    ```
- `GUI` 

    ```bash
    make win_simCapstats
    ```
    
ğŸ”¹ Multiple Tests (Sequential)

- `GUI` 

    ```bash
    make win_simMultiTest_seq
    ```
    
ğŸ”¹ Multiple Tests (Parallel)

- `Without GUI` 

    ```bash
    make win_simMultiTest_par
    ```

---


## ğŸ§ Running on Linux/macOS

### 1. Open Terminal

### 2. Clone the Repository

    ```
    git clone https://github.com/Abdelrahman1810/UVM-SAR-ADC.git
    cd UVM-SAR-ADC
    ```

### 3. Run the Simulation
ğŸ”¹ Single Test

- `Without GUI`

    ```
    make lnx_simSingleTest
    ```
- `GUI` 

    ```bash
    make lnx_simCapstats
    ```
    
ğŸ”¹ Multiple Tests (Sequential)

- `GUI` 

    ```bash
    make lnx_simMultiTest_seq
    ```
    
ğŸ”¹ Multiple Tests (Parallel)

- `Without GUI` 

    ```bash
    make lnx_simMultiTest_par
    ```

---

## ğŸ“Š Coverage & Logs
The UVM-SAR-ADC project incorporates both functional and code coverage metrics to assess the thoroughness of the verification process. Coverage data is generated during simulation and can be analyzed to identify untested scenarios or code segments.

### HTLM Report
![HTLM_General_coverage](Reports/HTLM_Report(1).png)
![HTLM_DUT_specifed](Reports/HTLM_Report(2).png)
![Transcript_summart_report](Reports/Summary_Report.png)

### Total Coverage: 95.90%

---

## â±ï¸ Verification Time Comparison
This section compares the simulation real-time duration for different test execution strategies used in the UVM-SAR-ADC project.

Mode | Description | Real Time | Pros | Cons
| --- | --- | --- | --- | --- |
`Single Test` | All sequences run inside one testbench session | 9.015 seconds | Simple setup  Easier debug | Longer simulation time
`Multiple Tests (Sequential)` | Each test runs independently, one after the other (serial execution) | 28.191 seconds | Modular testing  Isolated logs | Slower overall  No speedup
`Multiple Tests (Parallel)` | Each test runs in a separate simulation instance simultaneously (in parallel) | 6.415 seconds | Fastest overall  Best for coverage regression | Higher resource usage  Complex scripting



- Single Test (Only `user` and `sys` time is considered)

![SingleTest](Reports/Single.png)

---

- Multiple Test Sequential (Only `user` and `sys` time is considered)

![MultiTestSequential](Reports/Sequential.png)

---

- Multiple Test Parallel (Only `user` and `sys` time is considered)

![MultiTestParallel](Reports/Parallel.png)
---

### ğŸ“Œ How to Measure
You can measure simulation real-time by observing terminal output or appending time before the command:
```bash
time make <lnx_sim...>
```
> [!IMPORTANT]
> Before mesure time make sure remove:
> 
> All `#time` from test
>
> All comand exept the `vsim` one (e.g. remove `python3 extract.py`)

---

## ğŸ§‘â€ğŸ’»Contributing
If you find any issues or have suggestions for improvement, feel free to submit a pull request or open an issue in the repository. Contributions are always welcome!

---

## Contact info ğŸ’œ
<a href="https://linktr.ee/A_Hassanen" target="_blank">
  <img align="left" alt="Linktree" width="180px" src="https://app.ashbyhq.com/api/images/org-theme-wordmark/b3f78683-a307-4014-b236-373f18850e2c/d54b020a-ff53-455a-9d52-c90c0f4f2081.png" />
</a> 
<br>
<br>
